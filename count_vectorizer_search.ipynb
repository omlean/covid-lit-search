{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8cd64fb-2627-42f0-813f-5f62b46d0048",
   "metadata": {},
   "source": [
    "## Stage 0: Count vectorizer search\n",
    "Searching based on simple word counts in query and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41537eb-ff86-40f6-9fb6-03272cf69fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import preprocessing\n",
    "import my_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79082dcc-310e-49f6-80c9-bce52ad7714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorize(documents, pickle_path=None, save_files_prefix=\"\"):\n",
    "    \"\"\"Input:\n",
    "    documents: Series or List of strings to vectorize\n",
    "    pickle_path: path of directory to save vectorizer and term-document matrix, e.g. 'data/processed/'\n",
    "    save_files_prefix: prefix for saved files. For example, passing \"01\" will produce files '01_vectorizer.pkl' and '01_tdm.npz'\n",
    "    \n",
    "    Output: Fit vectorizer and term-document matrix\"\"\"\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(documents)\n",
    "    tdm = vectorizer.transform(documents)\n",
    "    \n",
    "    if pickle_path is not None: # save vectorizer and term-document matrix\n",
    "        \n",
    "        # if files by that name already exist, prompt user to choose another prefix. Repeats if new input still exists\n",
    "        while os.path.exists(pickle_path + save_files_prefix + \"_vectorizer.pkl\"):\n",
    "            save_files_prefix = input(\"Files by that name already exist. Enter another prefix...\")\n",
    "        \n",
    "        vec_path = pickle_path + save_files_prefix + \"_vectorizer.pkl\"\n",
    "        \n",
    "        with open(vec_path, 'wb') as file: # pickle vectorizer\n",
    "            pickle.dump(vectorizer, file)\n",
    "        print('Vectorizer pickled at ', vec_path)\n",
    "        \n",
    "        tdm_path = pickle_path + save_files_prefix + \"_tdm.npz\"\n",
    "        save_npz(tdm_path, tdm) # save term-document matrix\n",
    "        print('Term-document matrix saved at ', tdm_path)\n",
    "\n",
    "    return vectorizer, tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d6189-0192-43f7-a120-6b62630d6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/processed/metadata_clean.csv.gz'\n",
    "df = pd.read_csv(path, sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd00114-762e-4ce5-99fd-b9f77a354d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2a59b-49de-4ee9-9470-5d131d0463ce",
   "metadata": {},
   "source": [
    "### Vectorize search texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3f330-42bf-4520-8085-d37007f05150",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.search_text.tolist()\n",
    "path = 'results/final_models/'\n",
    "vectorizer, tdm = count_vectorize(documents, pickle_path=path, save_files_prefix=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958650ce-84ac-4103-9098-4465eaba953a",
   "metadata": {},
   "source": [
    "### Perform searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286e62d-84a6-4827-b7d9-e8bdbc8f9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectorizer and tdm\n",
    "path = 'results/final_models/cv_vectorizer.pkl'\n",
    "vectorizer = my_tfidf.load_vectorizer(path)\n",
    "tdm = load_npz('results/final_models/cv_tdm.npz')\n",
    "questions = pd.read_csv('data/processed/questions_expert.csv', sep='\\t').question.tolist()\n",
    "index = df.cord_uid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5801ad-7d08-403a-893c-891640a3de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='results/final_models/cv_2021/'\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    query = questions[i]\n",
    "    uids = my_tfidf.tfidf_search(query, vectorizer, tdm, index, df)\n",
    "    my_tfidf.write_details(query, uids, df,\n",
    "                               record_file_prefix=f'cv_{i}', \n",
    "                               directory=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61605bd7-4de1-4bb5-93f6-947ca0b0c0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
